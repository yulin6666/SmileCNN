{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this step we're going to use Keras. This will also start up your GPU if you're using one, which can take up to **10 seconds**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.4\n",
      "1.15.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Flatten, Reshape\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "print keras.__version__\n",
    "print tf.__version__\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's load the data, and convert the labels to categories. So `0` becomes `[1, 0]` and `1` becomes `[0, 1]`. This makes it easy to add more classes later (like \"angry\", \"sad\", etc.) and interpret the predictions as probabilities. We do this after loading the file instead of before saving to avoid having a big labels file on disk.\n",
    "\n",
    "Then we shuffle all the examples to make sure we don't hold out only one class for validation. And finally we count up how many instances there are of each class to make ensure that we put more emphasis on the rarer ones during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32 0.0 1.0 (36348, 32, 32, 1)\n",
      "float32 0.0 1.0 (36348, 2)\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "x_train = np.load('x_train.npy')\n",
    "y_train = np.load('y_train.npy')\n",
    "\n",
    "# convert classes to vector\n",
    "nb_classes = 2\n",
    "y_train = np_utils.to_categorical(y_train, nb_classes).astype(np.float32)\n",
    "\n",
    "# shuffle all the data\n",
    "indices = np.arange(len(x_train))\n",
    "np.random.shuffle(indices)\n",
    "x_train = x_train[indices]\n",
    "y_train = y_train[indices]\n",
    "\n",
    "# prepare weighting for classes since they're unbalanced\n",
    "class_totals = y_train.sum(axis=0)\n",
    "class_weight = class_totals.max() / class_totals\n",
    "\n",
    "print x_train.dtype, x_train.min(), x_train.max(), x_train.shape\n",
    "print y_train.dtype, y_train.min(), y_train.max(), y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we set up our network. It is based on the Keras `mnist_cnn.py` example, following in the footsteps of VGG net by using small 3x3 convolutions with max pooling, and a final stage of multiple dense layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 28, 28, 16)        416       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 10, 10, 16)        6416      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 64)                25664     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 32,626\n",
      "Trainable params: 32,626\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nb_filters = 16\n",
    "nb_pool = 2\n",
    "nb_conv = 5\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(nb_filters, (nb_conv, nb_conv), activation='relu', input_shape=x_train.shape[1:]))\n",
    "model.add(MaxPooling2D(pool_size=(nb_pool, nb_pool)))\n",
    "model.add(Conv2D(nb_filters, (nb_conv, nb_conv), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(nb_pool, nb_pool)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our data and model is ready, we can train the model on the data for a few epochs, holding out 10% of the data for validating the accuracy. This should take about **30 seconds**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "334/334 [==============================] - 30s 89ms/step - loss: 0.4122 - acc: 0.8229 - val_loss: 0.2908 - val_acc: 0.8779\n",
      "Epoch 2/20\n",
      "334/334 [==============================] - 28s 83ms/step - loss: 0.3195 - acc: 0.8668 - val_loss: 0.2585 - val_acc: 0.8920\n",
      "Epoch 3/20\n",
      "334/334 [==============================] - 32s 96ms/step - loss: 0.2826 - acc: 0.8835 - val_loss: 0.2197 - val_acc: 0.9188\n",
      "Epoch 4/20\n",
      "334/334 [==============================] - 29s 86ms/step - loss: 0.2608 - acc: 0.8947 - val_loss: 0.2030 - val_acc: 0.9199\n",
      "Epoch 5/20\n",
      "334/334 [==============================] - 28s 83ms/step - loss: 0.2457 - acc: 0.9004 - val_loss: 0.1963 - val_acc: 0.9216\n",
      "Epoch 6/20\n",
      "334/334 [==============================] - 26s 78ms/step - loss: 0.2346 - acc: 0.9040 - val_loss: 0.2043 - val_acc: 0.9157\n",
      "Epoch 7/20\n",
      "334/334 [==============================] - 29s 87ms/step - loss: 0.2284 - acc: 0.9077 - val_loss: 0.1869 - val_acc: 0.9240\n",
      "Epoch 8/20\n",
      "334/334 [==============================] - 31s 91ms/step - loss: 0.2239 - acc: 0.9091 - val_loss: 0.1947 - val_acc: 0.9226\n",
      "Epoch 9/20\n",
      "334/334 [==============================] - 30s 90ms/step - loss: 0.2165 - acc: 0.9117 - val_loss: 0.1822 - val_acc: 0.9288\n",
      "Epoch 10/20\n",
      "334/334 [==============================] - 29s 88ms/step - loss: 0.2119 - acc: 0.9138 - val_loss: 0.1783 - val_acc: 0.9295\n",
      "Epoch 11/20\n",
      "334/334 [==============================] - 30s 90ms/step - loss: 0.2097 - acc: 0.9146 - val_loss: 0.1709 - val_acc: 0.9305\n",
      "Epoch 12/20\n",
      "334/334 [==============================] - 29s 86ms/step - loss: 0.2072 - acc: 0.9177 - val_loss: 0.1805 - val_acc: 0.9288\n",
      "Epoch 13/20\n",
      "334/334 [==============================] - 29s 87ms/step - loss: 0.2050 - acc: 0.9174 - val_loss: 0.1662 - val_acc: 0.9312\n",
      "Epoch 14/20\n",
      "334/334 [==============================] - 26s 78ms/step - loss: 0.2025 - acc: 0.9170 - val_loss: 0.1668 - val_acc: 0.9350\n",
      "Epoch 15/20\n",
      "334/334 [==============================] - 28s 84ms/step - loss: 0.1984 - acc: 0.9185 - val_loss: 0.1732 - val_acc: 0.9333\n",
      "Epoch 16/20\n",
      "334/334 [==============================] - 29s 87ms/step - loss: 0.1972 - acc: 0.9211 - val_loss: 0.1691 - val_acc: 0.9336\n",
      "Epoch 17/20\n",
      "334/334 [==============================] - 30s 91ms/step - loss: 0.1934 - acc: 0.9218 - val_loss: 0.1882 - val_acc: 0.9295\n",
      "Epoch 18/20\n",
      "334/334 [==============================] - 29s 88ms/step - loss: 0.1921 - acc: 0.9227 - val_loss: 0.1711 - val_acc: 0.9371\n",
      "Epoch 19/20\n",
      "334/334 [==============================] - 39s 116ms/step - loss: 0.1928 - acc: 0.9218 - val_loss: 0.1728 - val_acc: 0.9278\n",
      "Epoch 20/20\n",
      "334/334 [==============================] - 40s 118ms/step - loss: 0.1906 - acc: 0.9237 - val_loss: 0.1592 - val_acc: 0.9374\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, X_val, y, Y_val = train_test_split(x_train,y_train, test_size=0.08, shuffle=True, random_state=2019)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "            rotation_range=15, \n",
    "            width_shift_range=0.1, \n",
    "            height_shift_range=0.1, \n",
    "            zoom_range=0.05)\n",
    "datagen.fit(X)\n",
    "    \n",
    "# reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "#                               patience=5, min_lr=0.001)\n",
    "# history = model.fit_generator(datagen.flow(X, y, batch_size=200), steps_per_epoch=len(X)/100, \n",
    "#                     epochs=100, validation_data=(X_val,Y_val),callbacks=[reduce_lr])\n",
    "\n",
    "history = model.fit_generator(datagen.flow(X, y, batch_size=200), steps_per_epoch=len(X)/100, \n",
    "                     epochs=20, validation_data=(X_val,Y_val))\n",
    "\n",
    "# validation_split = 0.10\n",
    "# history = model.fit(x_train, y_train, batch_size=128, class_weight=class_weight, epochs=50, verbose=1, validation_split=validation_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That got us to 90% validation accuracy, following the training accuracy pretty closely. To get it down more we might try tweaking the hyperparameters (number of filters, size of dense layers, etc.) or lowering the learning rate after a few epochs. But for now we will just save the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "open('gender_model.json', 'w').write(model.to_json())\n",
    "model.save_weights('gender_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visually check the accuracy and loss, we can plot them to verify that there aren't any unexpected kinks or noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32 0.0 1.0 (2000, 32, 32, 1)\n",
      "float32 0.0 1.0 (2000, 2)\n",
      "2000/2000 [==============================] - 0s 195us/step\n",
      "('loss:', 0.23045323610305787)\n",
      "('accuracy:', 0.916)\n"
     ]
    }
   ],
   "source": [
    "x_test = np.load('x_test.npy')\n",
    "y_test = np.load('y_test.npy')\n",
    "\n",
    "# convert classes to vector\n",
    "nb_classes = 2\n",
    "y_test = np_utils.to_categorical(y_test, nb_classes).astype(np.float32)\n",
    "\n",
    "# shuffle all the data\n",
    "indices = np.arange(len(x_test))\n",
    "np.random.shuffle(indices)\n",
    "x_test = x_test[indices]\n",
    "y_test = y_test[indices]\n",
    "\n",
    "print x_test.dtype, x_test.min(), x_test.max(), x_test.shape\n",
    "print y_test.dtype, y_test.min(), y_test.max(), y_test.shape\n",
    "\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(\"loss:\",loss)\n",
    "print(\"accuracy:\",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bonus (optional): let's check the area under the receiver operating characteristic curve (ROC AUC) so we can compare to other work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/envs/py2version/lib/python2.7/site-packages/tensorflow_estimator/python/estimator/api/_v1/estimator/__init__.py:12: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-0b10337b2886>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mn_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my_predicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mn_validation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mn_validation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_predicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "# from sklearn.metrics import roc_auc_score\n",
    "# n_validation = int(len(X_test) * validation_split)\n",
    "# y_predicted = model.predict(X[-n_validation:])\n",
    "# print roc_auc_score(y[-n_validation:], y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAAAAABWESUoAAADEElEQVR4nAXBS3MTRxAA4O6enn1pV9LKll8xGOOKU4RjKpWq/Okccs01xxxyBYIxpowQtiRrLe1jprvzfTjOx1VdFwm6/bZtNEBWzt9cVvto4eHv9yHnLIv93vUjj8slSpqk/nD2vXk1QUxPf/5IxM8by3w5PaxGZe8Ii7yuS18kRgRyVm8iY+7Jwro7Hl+e7Va9IpELTYSCwHzVRp4ldWG7p/1uejEsV/rBvlbz6x9daojK5QY4F+layZ7h9KjDmxVd7PJfytv5mAkdpbFj13+a3odxcjQvsL5KZgdv60nuKPFOLMmTwKHJq5+o3V7kyNl5XAxdH41TJgDjcZWwZkWeR7TzHNBPrirxI6eCQAIm47pkylIHNExm3ghL1q2qiARnJqLZ5JxdUaYQ2qvMBAl5FDsAk4DeRAIVB4zsnYT8DQxMGgbJTEFNBUBCJxNmMgUNBxgy6GFYOvaChBoVwhCw8pxEjaK72zQpE3KxzbxzDhTEYq++RJ5/7iFGvdMW88uiWHVI4gAMRIiIcj77vDcZ0g25m9vffq/yXgyAkBTImwHweLQbNDTYwNtfO1+7BoyBHIBDFLMbxrP3IQYL08xfl4mOsHVIaA7USFQfyU7IBF0ym27S0PaRE0dgaOQcGHZTxqJ8AvQ0PdV2ClEU0BEioKlqVGaA4ycgjv8uDu+rwxM/pBkiGEQzkeB7Bjj5LyYWw6LLEswKuX5doQKoyNC3Zzs2Kmff3WaTH53Xp0fYtLJPkURBh67J0oEB9HJtybj+YXpYg3slDWhwYDa0m+FofcdgcHiwgCQsHj9eXB5smZEAxMJ+9fiyezclBLRrAmKmuFw9dULeO5V+++1Lgff/PDAAwPjFB+Jk7AkdAiFZ7LbfFtOy+bQDBjDU69uI+fy4SlMixBien+7W48mw+tpkDIAA6cEyxmGfZx6Q5Hn/cD+MalgvH7d7BgCwv969iE2mYY6OdHh42GBZUrvZNDIwIAx/Lm1x3jayD9uK+vUa86Rk6dpNq89s1v3RgLVfXvY0hCLR1k3KlCkOsd8J4v/bhsFAohv0fgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "from utils import show_array\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras.models import model_from_json\n",
    "model1 = model_from_json(open('model.json').read())\n",
    "model1.load_weights('weights.h5')\n",
    "\n",
    "X = np.load('x_test.npy')\n",
    "class_names = ['Neutral', 'Smiling']\n",
    "img = X[-7]\n",
    "show_array(255 * img)\n",
    "\n",
    "print(X[100:1000].shape)\n",
    "\n",
    "probabilities = model1.predict(X[100:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:TensorFlow version 1.15.0 detected. Last version known to be fully compatible is 1.14.0 .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : conv2d_9_input, <keras.engine.input_layer.InputLayer object at 0xb449fc8d0>\n",
      "1 : conv2d_9, <keras.layers.convolutional.Conv2D object at 0xb449fc750>\n",
      "2 : conv2d_9__activation__, <keras.layers.core.Activation object at 0x1a531dd0d0>\n",
      "3 : max_pooling2d_9, <keras.layers.pooling.MaxPooling2D object at 0x1a526835d0>\n",
      "4 : conv2d_10, <keras.layers.convolutional.Conv2D object at 0x1a52f11650>\n",
      "5 : conv2d_10__activation__, <keras.layers.core.Activation object at 0x1a531ee6d0>\n",
      "6 : max_pooling2d_10, <keras.layers.pooling.MaxPooling2D object at 0x1a52f19910>\n",
      "7 : flatten_5, <keras.layers.core.Flatten object at 0x1a52f1fb90>\n",
      "8 : dense_13, <keras.layers.core.Dense object at 0x1a52f3a4d0>\n",
      "9 : dense_13__activation__, <keras.layers.core.Activation object at 0x1a531ee910>\n",
      "10 : dense_14, <keras.layers.core.Dense object at 0x1a52f464d0>\n",
      "11 : dense_14__activation__, <keras.layers.core.Activation object at 0x1a531ee990>\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAAAAABWESUoAAADdElEQVR4nAXBy4uVZRgA8Od53vd7v8s537mP49GjnnKsJC0DCUEisIQiiGrVPqpNtesfaOuiTasgchHSwk0gQruIaNN4A0elbBSbcZw5czvnu5zv8r7P0++HS+9faER+FLFPihwwiwVkkargyk4f/Khbi7HZvAtPVfv1V0KLLFYUM7JDRor6RrdfDMreuey5B/f3vn/j7CECBRUAuNpZJFqYab8VRDokPF/8e2Oy8mSpHYFzTnJUCpQ0ct2KDFDlEcuh3mqeZUaBtZxNZ2x6MUaVHhoFebLlbUany1FVOnFkXbK5uv54ktiXvir0MeWpZ48vX1i61H/vZTTAznK6vd84etTTs0ffGX1Qe/r5xten3unf/jgPyPOA51tT7PrdiOHdGzd1mxD0IN44cfPY6ParKmpgtjetwmR5+bXRWVwMNBEpYRh8M83ScRybhpomHE4vfXBArm+8lYYEKEiRXlvfycJxt9kIqJbBcGqu3P0sWHebRisEJtU4zhWoAGpP1dCNi4uDny/e+3A8/GFJi2UGREUekoBSVOvY6Envc46Otnt3viRxzgEDeQoAhBSQCUw0CneTiTPpySP4yyiOUBGIOCEFPqZ7NSrlGAmDqy3W0wVDRhDLeRK1bQDsvNwD0iwACtRAPzwSoNVQpnPT1E5EpN4JWhqBxU5ir9R33s5qQJfNY0ASQGfL9jM/sMI2X0kx1etQO+RM9f0qIdZSFr6axSoQy3neQdZp4iM6aXTCfGt53DfVroog8UVc/V/OsdHp5U9AOUh60gw6a6utnZ2id5CTqHTzWyMHKfbp21azQLW6NFLz3e3diuKGg9Jw9mSNDvuAI//EF2DChWL578XxWJVpydV+pSkp/jwCqeniocB8dL7j+SQrxfqTGptclMcXdDn5oyNhV5H2+/L7C2FsHZ1+lDcx3ddnOntecfdhIM3OVltwcLCpTr5/2KsU17PZjrQ8l5X2t5kPxjWRFdkphGu39oEsCtNwqJTj+to2KJ+JK99Qvb8xD27fnGsUvxV7QCXYn5xv8z2Viq5TDfPtgEd/0bnIMqq6Zti4ElYHKO1xK3IW9fCp3m3uHb7vzlsrZSZ83ddgLHXNTHKfI/z0H/HGPqLaOjXyHa9cW3jz14BgEMxnoW8blUZ9hoaJtZP66r0C9ekDi1EgGMxK22cI59H/D2vM594YnjYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=32x32 at 0x1A52664C10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Female\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAAAAABWESUoAAADLUlEQVR4nCXMzW4cRRAA4Krqmu6emf3xetdrG2I5TmS4ONjKyooIiAPJhQMSZ3gCXoDn4J4Ll0goB0A8ARzIJZDERkEhSBHiRwkOG6833tmZ6e4qDnwP8OFmbdKq+NfPLu5v+MqvmTY++LvoX9jx8Zu7txk5oRrQNLxyaVhC2ZHpUz64IcmCizfvUYuMLCTr6wfjlZyV3WJ1K89ICVuKF0ZOiAFd4X1/biDLDbM3RQoNOOeS1IeAwJSDqcCWl3rLLjvOWNpZKrglJp7MjGXIzdy+vTcsfVQ2jiDNp0Sxm4rMbKeFZx1O+zcnfY7IscmAU5x999Ubt++uEBL6owlPe8vDKy4pNCgte4nVr51i+cump0RYjx3mH2TvrFeZt2nRzDd2i6Y5PfHr6xoBM1haw4TjYn7eK57VVfEq27TGrrlo5o4REP3RhD79qxNfnt/55PHVnyEzdWTrBquWgIwhkAx5bVzUfPT+g28Hb4HTEByDCQyGjAFNXcDPX3jXRO7mFfhohuM+O4kCJiOD2AbLxf3rWBpniSnG2Cyxw5wAEQgBwCLp7hR9medFwQqIarA6AxVEUAIFpfzwHySXl4VHbRM5lzkOkhTRgCISGfowKbIh6zWQMPYG4yFAQCIFQiVjoJNiVGTfpWIg2D76vkJGAQFABSLk0VmbBND3O1fvPJqe5dtzQiNJEVSUiIyOqiaqKHfu3ahPFzbHpKoAohoCESkNFu2ylVgnOc2AW+IMQVVAk7MMCEDv/mAoaQgROIWmNBYAUCiJKJMqYnhtkZykCOz45eBf++z3gw5hAhAkAFTga9N6UQfJXS8LMDtuL+agGpcKwKqqgvV7P6aMut0nXww2Drb2acUYhfD0+KMufg2SaNzT4xPOB/r4+drlke9aw0Tp1FznNVZVUAXYe/icVbYvG2/OiTNCrUFV54wKoElQd7tH5CXgWTlwGQGEGpZv/pZIVf9PeOfLh7M2VSFzJCm2M1H4OAkpAGgSCfevndz6Y9pwaSgs61cvIqiWO8KCqqrS+eynooH0Z3+3tE1aQrIkOG8mJyygEiPuF9LKXrSLJ1ujzDilyKmaV0H+AxQUqEzthDAJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=32x32 at 0x1A52664C10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male\n"
     ]
    }
   ],
   "source": [
    "#coreml模型\n",
    "from utils import show_array\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import IPython.display\n",
    "\n",
    "import keras\n",
    "from keras.models import model_from_json\n",
    "model = model_from_json(open('gender_model.json').read())\n",
    "model.load_weights('gender_weights.h5')\n",
    "\n",
    "from keras.models import load_model\n",
    "import coremltools\n",
    "\n",
    "import coremltools\n",
    "\n",
    "coreml_model = coremltools.converters.keras.convert(model,input_names='data', image_input_names='data',output_names='outTensor')\n",
    "coreml_model.save('gender.mlmodel')\n",
    "\n",
    "# X = np.load('X.npy')\n",
    "# Y = np.load('Y.npy')\n",
    "class_names = ['Female', 'Male']\n",
    "# img = X[-8]\n",
    "# show_array(255 * img)\n",
    "\n",
    "#check female\n",
    "# raw_img = 255*img\n",
    "# raw_img = np.squeeze(raw_img)\n",
    "# raw_img = np.uint8(np.clip(raw_img, 0, 255))\n",
    "# img = PIL.Image.fromarray(raw_img)\n",
    "img = PIL.Image.open('../dataset/Gender/testdata/Female/b12_8.jpg')\n",
    "newsize = (32, 32) \n",
    "img = img.resize(newsize) \n",
    "display(img)\n",
    "\n",
    "mlmodel = coremltools.models.MLModel('gender.mlmodel')\n",
    "out = mlmodel.predict({'data': img})\n",
    "ret = out['outTensor']\n",
    "print class_names[np.argmax(ret)]\n",
    "\n",
    "#check male\n",
    "img = PIL.Image.open('../dataset/Gender/testdata/Male/b12_170.jpg').convert('L')\n",
    "newsize = (32, 32) \n",
    "img = img.resize(newsize)\n",
    "display(img)\n",
    "\n",
    "mlmodel = coremltools.models.MLModel('gender.mlmodel')\n",
    "out = mlmodel.predict({'data': img})\n",
    "ret = out['outTensor']\n",
    "print class_names[np.argmax(ret)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
