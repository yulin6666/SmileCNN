{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this step we're going to use Keras. This will also start up your GPU if you're using one, which can take up to **10 seconds**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.4\n",
      "1.15.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Flatten, Reshape\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "print keras.__version__\n",
    "print tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's load the data, and convert the labels to categories. So `0` becomes `[1, 0]` and `1` becomes `[0, 1]`. This makes it easy to add more classes later (like \"angry\", \"sad\", etc.) and interpret the predictions as probabilities. We do this after loading the file instead of before saving to avoid having a big labels file on disk.\n",
    "\n",
    "Then we shuffle all the examples to make sure we don't hold out only one class for validation. And finally we count up how many instances there are of each class to make ensure that we put more emphasis on the rarer ones during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32 0.0 1.0 (38348, 32, 32, 1)\n",
      "float32 0.0 1.0 (38348, 2)\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "X = np.load('X.npy')\n",
    "y = np.load('y.npy')\n",
    "\n",
    "# convert classes to vector\n",
    "nb_classes = 2\n",
    "y = np_utils.to_categorical(y, nb_classes).astype(np.float32)\n",
    "\n",
    "# shuffle all the data\n",
    "indices = np.arange(len(X))\n",
    "np.random.shuffle(indices)\n",
    "X = X[indices]\n",
    "y = y[indices]\n",
    "\n",
    "# prepare weighting for classes since they're unbalanced\n",
    "class_totals = y.sum(axis=0)\n",
    "class_weight = class_totals.max() / class_totals\n",
    "\n",
    "print X.dtype, X.min(), X.max(), X.shape\n",
    "print y.dtype, y.min(), y.max(), y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we set up our network. It is based on the Keras `mnist_cnn.py` example, following in the footsteps of VGG net by using small 3x3 convolutions with max pooling, and a final stage of multiple dense layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/envs/py2version/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/py2version/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/py2version/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/py2version/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/py2version/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/py2version/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/py2version/lib/python2.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/py2version/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 30, 30, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               802944    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 812,770\n",
      "Trainable params: 812,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nb_filters = 32\n",
    "nb_pool = 2\n",
    "nb_conv = 3\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(nb_filters, (nb_conv, nb_conv), activation='relu', input_shape=X.shape[1:]))\n",
    "model.add(Conv2D(nb_filters, (nb_conv, nb_conv), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(nb_pool, nb_pool)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our data and model is ready, we can train the model on the data for a few epochs, holding out 10% of the data for validating the accuracy. This should take about **30 seconds**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/envs/py2version/lib/python2.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/py2version/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/py2version/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/py2version/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Train on 34513 samples, validate on 3835 samples\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/py2version/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/py2version/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/py2version/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/py2version/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/py2version/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "34513/34513 [==============================] - 46s 1ms/step - loss: 0.3191 - acc: 0.8659 - val_loss: 0.2403 - val_acc: 0.9022\n",
      "Epoch 2/25\n",
      "34513/34513 [==============================] - 44s 1ms/step - loss: 0.2465 - acc: 0.9008 - val_loss: 0.2115 - val_acc: 0.9132\n",
      "Epoch 3/25\n",
      "34513/34513 [==============================] - 41s 1ms/step - loss: 0.2186 - acc: 0.9124 - val_loss: 0.2001 - val_acc: 0.9197\n",
      "Epoch 4/25\n",
      "34513/34513 [==============================] - 41s 1ms/step - loss: 0.1955 - acc: 0.9226 - val_loss: 0.1786 - val_acc: 0.9286\n",
      "Epoch 5/25\n",
      "34513/34513 [==============================] - 40s 1ms/step - loss: 0.1785 - acc: 0.9309 - val_loss: 0.1739 - val_acc: 0.9272\n",
      "Epoch 6/25\n",
      "34513/34513 [==============================] - 41s 1ms/step - loss: 0.1651 - acc: 0.9367 - val_loss: 0.1582 - val_acc: 0.9377\n",
      "Epoch 7/25\n",
      "34513/34513 [==============================] - 42s 1ms/step - loss: 0.1549 - acc: 0.9394 - val_loss: 0.1552 - val_acc: 0.9390\n",
      "Epoch 8/25\n",
      "34513/34513 [==============================] - 40s 1ms/step - loss: 0.1460 - acc: 0.9439 - val_loss: 0.1489 - val_acc: 0.9419\n",
      "Epoch 9/25\n",
      "34513/34513 [==============================] - 40s 1ms/step - loss: 0.1342 - acc: 0.9488 - val_loss: 0.1545 - val_acc: 0.9369\n",
      "Epoch 10/25\n",
      "34513/34513 [==============================] - 40s 1ms/step - loss: 0.1281 - acc: 0.9507 - val_loss: 0.1522 - val_acc: 0.9359\n",
      "Epoch 11/25\n",
      "34513/34513 [==============================] - 40s 1ms/step - loss: 0.1246 - acc: 0.9515 - val_loss: 0.1522 - val_acc: 0.9372\n",
      "Epoch 12/25\n",
      "34513/34513 [==============================] - 40s 1ms/step - loss: 0.1174 - acc: 0.9552 - val_loss: 0.1443 - val_acc: 0.9452\n",
      "Epoch 13/25\n",
      "34513/34513 [==============================] - 43s 1ms/step - loss: 0.1083 - acc: 0.9578 - val_loss: 0.1427 - val_acc: 0.9473\n",
      "Epoch 14/25\n",
      "34513/34513 [==============================] - 47s 1ms/step - loss: 0.1016 - acc: 0.9611 - val_loss: 0.1415 - val_acc: 0.9471\n",
      "Epoch 15/25\n",
      "34513/34513 [==============================] - 43s 1ms/step - loss: 0.0963 - acc: 0.9629 - val_loss: 0.1477 - val_acc: 0.9416\n",
      "Epoch 16/25\n",
      "34513/34513 [==============================] - 44s 1ms/step - loss: 0.0901 - acc: 0.9655 - val_loss: 0.1475 - val_acc: 0.9502\n",
      "Epoch 17/25\n",
      "34513/34513 [==============================] - 40s 1ms/step - loss: 0.0876 - acc: 0.9668 - val_loss: 0.1446 - val_acc: 0.9460\n",
      "Epoch 18/25\n",
      "34513/34513 [==============================] - 40s 1ms/step - loss: 0.0817 - acc: 0.9686 - val_loss: 0.1594 - val_acc: 0.9452\n",
      "Epoch 19/25\n",
      "34513/34513 [==============================] - 40s 1ms/step - loss: 0.0776 - acc: 0.9709 - val_loss: 0.1472 - val_acc: 0.9499\n",
      "Epoch 20/25\n",
      "34513/34513 [==============================] - 40s 1ms/step - loss: 0.0745 - acc: 0.9717 - val_loss: 0.1562 - val_acc: 0.9437\n",
      "Epoch 21/25\n",
      "34513/34513 [==============================] - 40s 1ms/step - loss: 0.0695 - acc: 0.9732 - val_loss: 0.1587 - val_acc: 0.9473\n",
      "Epoch 22/25\n",
      "34513/34513 [==============================] - 41s 1ms/step - loss: 0.0667 - acc: 0.9751 - val_loss: 0.1567 - val_acc: 0.9505\n",
      "Epoch 23/25\n",
      "34513/34513 [==============================] - 41s 1ms/step - loss: 0.0646 - acc: 0.9761 - val_loss: 0.1514 - val_acc: 0.9497\n",
      "Epoch 24/25\n",
      "34513/34513 [==============================] - 40s 1ms/step - loss: 0.0631 - acc: 0.9768 - val_loss: 0.1572 - val_acc: 0.9518\n",
      "Epoch 25/25\n",
      "34513/34513 [==============================] - 47s 1ms/step - loss: 0.0587 - acc: 0.9776 - val_loss: 0.1673 - val_acc: 0.9476\n"
     ]
    }
   ],
   "source": [
    "validation_split = 0.10\n",
    "history = model.fit(X, y, batch_size=128, class_weight=class_weight, epochs=25, verbose=1, validation_split=validation_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That got us to 90% validation accuracy, following the training accuracy pretty closely. To get it down more we might try tweaking the hyperparameters (number of filters, size of dense layers, etc.) or lowering the learning rate after a few epochs. But for now we will just save the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "open('gender_model.json', 'w').write(model.to_json())\n",
    "model.save_weights('gender_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visually check the accuracy and loss, we can plot them to verify that there aren't any unexpected kinks or noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bonus (optional): let's check the area under the receiver operating characteristic curve (ROC AUC) so we can compare to other work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0b10337b2886>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mn_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my_predicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mn_validation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mn_validation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_predicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "n_validation = int(len(X) * validation_split)\n",
    "y_predicted = model.predict(X[-n_validation:])\n",
    "print roc_auc_score(y[-n_validation:], y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/envs/py2version/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/py2version/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/py2version/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/py2version/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:131: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/py2version/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/py2version/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/py2version/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/py2version/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/py2version/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/py2version/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/py2version/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/py2version/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAAAAABWESUoAAAC1UlEQVR4nAXBWXIbVRQA0Du9oQfJsh1TTggfEAr+2RibYj+wAQpSBRXslCxbUne/6b7LOfhrnPOpxSHeTJMnvpSDOiVC0FLMff0sLVtO+Tq4627aR7d6Uy9NibQTYs4CTeYdQts2IOmMfM6ZOjMgOYXcJcTBB6x9qChglZcCaiwIOCAZgEj0vOSiwGqdrfRqDqrWivMQBwgSRuxvfLt7OvlkPUjJvaSXsg4E491H2ktgTvjtoz1/fnynXofp9PWo7nB37IdpHiYQ0Nbu7fT0h4m4RtptGffx07vfTrCb465Ib8aMKfys3hNAQcRHO/Tf/zpMIMyTCKFhK/RQVYlafL8+LYdzXX8Zxr2gv4hU5OQCoWCBZM6NsZRQDjeEY/CpSSnBQ0PhWJJW7imMqojoxmEEcFG24Pw+VcK0rF0ZO83FBReGQUANWcTxPFpvUMx1ps60x3kWcwGymkRxHfsmc1cszWCYPE1yw5gNDMU4ikbadKrn/ApsHYixLWUX2Soid+jSiSse12QthNVBb+za8fXgBTlI4Sagree2DRFASPwgLUzHYzpEQpNERVSbne2AFk+vIVpJjd6O7+HSPFQr8SJONMfAubvb9aWPp0X++Te0MeUKYkM9iuMWA1UGpWl6/pPw+vYwZsIVpVK8XInIB6gNOAY3/Djz4n7wXbdqtVexcxbRSa1+6W4ILu0+QIVTgezFs+ShnUn8pgLZX+++2Z3W5WqCX470YXJT3Ai2xOKaEccHxu3+e5Yz5Otz+u5jFI815KIqik2Q5S6d/gs3+0zPf9tPD6LRpzaua+5SqCtCMAuuL8myfkQk9VJOLqelkRRvTb35XVPnhRptL47Vtlfzl1ICSBUoIMa+gjjvJS/BOy3XbV7zVj1JCVT7iCBj7SWDU57Ep+N6X0tpBE0uQ9CaR8ZBVJsZBXKSljvLujIDyjXcYk+OGQWRFZwELGeC1Bf0gO1/P3jCBcc8n9kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils import show_array\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras.models import model_from_json\n",
    "model1 = model_from_json(open('model.json').read())\n",
    "model1.load_weights('weights.h5')\n",
    "\n",
    "X = np.load('X.npy')\n",
    "class_names = ['Neutral', 'Smiling']\n",
    "img = X[-7]\n",
    "show_array(255 * img)\n",
    "\n",
    "print(X[100:1000].shape)\n",
    "\n",
    "probabilities = model1.predict(X[100:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : conv2d_1_input, <keras.engine.input_layer.InputLayer object at 0x1c46bf8790>\n",
      "1 : conv2d_1, <keras.layers.convolutional.Conv2D object at 0x1c46bf8d90>\n",
      "2 : conv2d_1__activation__, <keras.layers.core.Activation object at 0x1c46bf8210>\n",
      "3 : conv2d_2, <keras.layers.convolutional.Conv2D object at 0x1c46c00e10>\n",
      "4 : conv2d_2__activation__, <keras.layers.core.Activation object at 0x1c3ff9e650>\n",
      "5 : max_pooling2d_1, <keras.layers.pooling.MaxPooling2D object at 0x1c46c0dcd0>\n",
      "6 : flatten_1, <keras.layers.core.Flatten object at 0x1c46c1e350>\n",
      "7 : dense_1, <keras.layers.core.Dense object at 0x1c46c32ad0>\n",
      "8 : dense_1__activation__, <keras.layers.core.Activation object at 0x1c46c69c90>\n",
      "9 : dense_2, <keras.layers.core.Dense object at 0x1c46c44590>\n",
      "10 : dense_2__activation__, <keras.layers.core.Activation object at 0x1c46c6ff50>\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAAAAABWESUoAAADI0lEQVR4nAXB22pcVRgA4P+01tp7zzknQxpbiZZ4AKlIVcSL0DfwzqfxLbzzok/ghQoFeytSKr2oVClYalJIkzTNTGZmz559WOv//T68aXtRwMlwuLXbL4iJoV6fLs8T9TZjRVOx9fVEoupc4/rAsYpCeXLeuOHuzoCWJ39L5z94byOkctkiV6FQEq3oRphMci80Lp5IvL0biLLB5nzRvmV2oBEc9IITF9puHYl9G7sOwuatDUmrBgwMkksKvkcaZyiIlYsNbRV72/Wlq/vs2yWUzaym6fFNKGuRtCiL7PrF/mTRmy36Ow6jrhcv/4lu9FVRtiYwmMenPi//+vXobu+8ShlPjedltuJv/5h9Jkhdf3TKn0y6Idx5uMUJQ55NzuxWpC+ze98cuiid7l6oHvj5veUROUVGHn4xvfiuz3mxp4NOYou3r7r5YDuSMwDxFryO8g6y0TirfSVavjMZIYaQeazAjCyEMK3AhV4RyJUCS+oDspDjtkymmnuWEdQkLKwpil6pZYQAmOraFIOTpKnomctEuikIXZYDCASooE3MQVHmhuK7TGi9PiGyZtUpkBchaLoAwEnPVi0M0LqEjxIZvlqlROC99zE4bkj2mqRtSaSxeWME8t9inQyRsCuG6/Xs5UpCm9RSMvjdgaBW86HzDtBoMT7tLK3eJQIVRUw/KwsAHo+KmgJByJ/FRvYpHV62mpjSxVpZyPj0sAyCGRQf7c0+vfqw8CzTDqLBj2woiByvQuaSMeeyceC9F5XMQPX8BbMJI7jn26WzOs8oOaFIbRcB0Zr7eRlASJHbM8WY3qbivHy6/yjeeb9EwvjvMbApbiQC645gpnVrC9vxuBiN889vhOn3eYVIOFFGrvjrTKdSBymKIUzGg1UO948BLeUECJBEH1cyAm7IlpUVPePr355Lp0ggCEaQVc2TuxLYyDz1VynSs4eSSBUYx8DGkCIOP+7TJJetnrd18+AxkDdU7hGgCqgQ0qslFP29rOj18ac/ASkBGKIAsCJqSOiuoe+WmPr1D68pcqiBjVAQzSmQ+UHumgsDWr3+5Q13qIksEcD/JnauffR7ltQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=32x32 at 0x1C46B822D0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Female\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAAAAABWESUoAAAARGVYSWZNTQAqAAAACAABh2kABAAAAAEAAAAaAAAAAAADoAEAAwAAAAEAAQAAoAIABAAAAAEAAAGYoAMABAAAAAEAAAGYAAAAAM1Ra5MAAAOpSURBVHicBcFJaFxlAADgf3vbvJl5Ly+ZZDqTJjqJtEkXahorVAPSppVQCuJBEfQgohQUoXoogoILePCmnmpPihaPFS0KrUhtKFRTjDYWqqZZJntmebO85d/9PqjYF38eQ4ab9ZdXugT0CGa3QCtC7ii+WL4ANVTq7HQOKPjHbk0UfCNrdny6GdINt/wC+/Y9AIgSewWTud8WYu6H3DCRp5BXwoVo/dezDyMFCPsraCJ2lw47JKG25jaEVNUGkiVwVPQACIj1te3M/4DfVpSkUfrj6JiXm9+woDw00kuPzhQQbL5uz26fB4audQ3GIP4p0uRkfC8pH3sJEfhsl8jqpwcuaU4bv3Tz7IgL4PnM+/YCM1/9HLxogY9vo83mtL9DRO3aRBAdv42ZfDBHrMOT+64dhjcX0NpnZFnk4nPdsHqkOWZ2ptmNSqXvTsGkwOgfHQL3XEm64XMbBgmKtBsi3/bzp3PWB2+8ZkOzb8vuGX9mCp16er5cur6vSNyilXfsrcDm3Ha1I9aRyqrnLyP01iJw31xODEhyueji6VJEncuLIe71DIOfCTyoP0qGcLfLv2RanDLV46txZmg0c6knaPeXB8udK0SnlEQtol52ULq1MVbdMWV84ZUGSIuWgrXsGSJDISlUlmWF22GY3FyYfOTv6v22bUtpKwdmCDpQwwpIhwttYb9VKsDOo8fjYY6F1pyBD5E+xzsCYA2SmKX9m7uWuUfMPPHYqJAxRcQ6SBS0KdMmg0qpQdvvpHm1njc84u9qKVP3Z4T0SYQNKJkAMIsT5DlBX9fOQrfsJi1iYALAxHVJGGRCZBXn+UXKK2uth/yVgTzDVI0QBR7gDEOccIM0FJqTYHMdGX5BHSx7kMJbBIBBRZB0fi9mlFqrV6eCMcPMFxdv9AeuoWGJAG0gpKGsGJi1a+MTJqDNPj8o7V9KCcRhnSigp7+ziHA5g4UgDommggHYaw+nVJtXWwgotb+TpInQMIFE6yhMIUpDwTKelOKbETKDTjwZmRAoHRlK2FgZIDNIrRRjQXTLzpL6uwOgt+0IwFFiQSTyCOr2sI1dRaWc5f+htt9IpqTQnHPEEMlmTc1pC7t2BrI9n+TL6CvZFHN7m1QwobQQWsd1kCz9u51C7jxl5bbRyv3KrUw0zoSmiZCCRgxzA+zurNbBFYrNCsJRFNQ93uBa0VY3jjhlnXpMV5uh4b0DGh68+n1jsro0nPvHUAB0LUZQzUPazB1Cs/BEG979H3CB+R6edmoNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=32x32 at 0x1C46B822D0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male\n"
     ]
    }
   ],
   "source": [
    "#coreml模型\n",
    "from utils import show_array\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import IPython.display\n",
    "\n",
    "import keras\n",
    "from keras.models import model_from_json\n",
    "model = model_from_json(open('gender_model.json').read())\n",
    "model.load_weights('gender_weights.h5')\n",
    "\n",
    "from keras.models import load_model\n",
    "import coremltools\n",
    "\n",
    "import coremltools\n",
    "\n",
    "coreml_model = coremltools.converters.keras.convert(model,input_names='data', image_input_names='data',output_names='outTensor')\n",
    "coreml_model.save('gender.mlmodel')\n",
    "\n",
    "# X = np.load('X.npy')\n",
    "# Y = np.load('Y.npy')\n",
    "class_names = ['Female', 'Male']\n",
    "# img = X[-8]\n",
    "# show_array(255 * img)\n",
    "\n",
    "#check female\n",
    "# raw_img = 255*img\n",
    "# raw_img = np.squeeze(raw_img)\n",
    "# raw_img = np.uint8(np.clip(raw_img, 0, 255))\n",
    "# img = PIL.Image.fromarray(raw_img)\n",
    "img = PIL.Image.open('../dataset/Gender/cropImage/Female/b12_23.jpg')\n",
    "newsize = (32, 32) \n",
    "img = img.resize(newsize) \n",
    "display(img)\n",
    "\n",
    "mlmodel = coremltools.models.MLModel('gender.mlmodel')\n",
    "out = mlmodel.predict({'data': img})\n",
    "ret = out['outTensor']\n",
    "print class_names[np.argmax(ret)]\n",
    "\n",
    "#check male\n",
    "img = PIL.Image.open('../dataset/Gender/testdata/yl.jpg').convert('L')\n",
    "newsize = (32, 32) \n",
    "img = img.resize(newsize)\n",
    "display(img)\n",
    "\n",
    "mlmodel = coremltools.models.MLModel('gender.mlmodel')\n",
    "out = mlmodel.predict({'data': img})\n",
    "ret = out['outTensor']\n",
    "print class_names[np.argmax(ret)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
